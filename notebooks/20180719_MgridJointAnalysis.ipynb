{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /home/schlecker/repos/planeteScripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import output\n",
    "import plots\n",
    "import stats\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# default output folder\n",
    "outputs = '/home/schlecker/phd/planete/outputs/pop06_MstarGrid/'\n",
    "# outputs = '/media/martin/Daten/phd/planete/outputs/pop06_MstarGrid/'\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initiate the 'master' population with subpopulations for each stellar mass\n",
    "All ref_red data will be in one multiindex-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = ['ref_red5e9_0.3Msol.dat', 'ref_red5e9_0.5Msol.dat', \n",
    "             'ref_red5e9_0.7Msol.dat', 'ref_red5e9_1.0Msol.dat'] \n",
    "fileList = [outputs + f for f in filenames]\n",
    "Mgrid = output.Population(fileList, name='Mgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mgrid.get_typeStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how about a summary plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_typeStats(populations):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(populations, list):\n",
    "        stats = {p.name : p.get_typeStats() for p in populations}\n",
    "        fig, ax = plt.subplots()\n",
    "        stellarMasses = [0.3, 0.5, 0.7, 1.0]\n",
    "        for M, Mstar in enumerate(stats.keys()):\n",
    "            for planetType in stats[Mstar]:\n",
    "                plt.errorbar(stellarMasses[M], stats[Mstar][planetType]['meanMetallicity'], stats[Mstar][planetType]['stdMetallicity'],\n",
    "                             capsize=40., fmt='o', label=planetType)\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## disk lifetime analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tDiskFiles = [outputs + s for s in ['ref_redtdisk_0.3Msol.dat','ref_redtdisk_0.5Msol.dat', 'ref_redtdisk_0.7Msol.dat', 'ref_redtdisk_1.0Msol.dat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mgrid = output.Population()\n",
    "Mgrid.read_tDiskData(tDiskFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute disk fractions and store them separately for each Mstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diskFractions = {Mstar : utils.get_diskFractions(tDiskData, Ntimes=50) for Mstar, tDiskData in Mgrid.tDiskData.groupby(level=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit exponential function to disk fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parametrize the fraction of remaining disks, we apply a simple exponential fit of the form f(t) = A*exp(-t/tau) + C. There is a clear trend of increasing disk lifetimes with increasing stellar mass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipdb; ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax, diskFractions, tau, std_tau = plots.plot_diskFractions(diskFractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the trend in 'tau'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mstar = [float(key[:-4]) for key in diskFractions.keys()]\n",
    "# tau = [m[2][1] for m in diskFractions.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = plots.plot_diskLifetimeComparison(Mstar, tau, std_tau, nSigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we see that the scaling of tau is positive and linear in host star mass. This contradicts the findings of Ribas et al. (2015), who not only find a negative trend with some significance, but also report typical infrared excess decay times of ~(2-6)Myr, which is consistently lower than our values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mstar-dependent histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_multiHistogram(dataFrame, columnNames, ax=None, **kwargs):\n",
    "    \"\"\" Plot multiple histograms from a dataFrame into the same axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataFrame : pandas DataFrame\n",
    "        dataFrame containing column(s) stated in 'columnNames'\n",
    "    columnNames : str or list\n",
    "        name(s) of the column(s) to plot.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ax : matplotlib axis\n",
    "        axis with the plot\n",
    "    \"\"\"\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    mplKwargs = {'alpha' : 0.3}\n",
    "    \n",
    "    if isinstance(columnNames, list):\n",
    "        # plot different columns of the same dataFrame        \n",
    "        for name in columnNames:\n",
    "            ax.hist(dataFrame[name], label=name, **mplKwargs, **kwargs)\n",
    "    \n",
    "    elif isinstance(columnNames, str):\n",
    "        # assume that dataFrame is multiindexed, iterate over outermost level\n",
    "        for label, subpopulation in dataFrame.groupby(level=0):\n",
    "           ax.hist(subpopulation[columnNames], label=label, **mplKwargs, **kwargs)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "\n",
    "# test\n",
    "# group = Mgrid.tDiskData.groupby(level=0)\n",
    "# tDiskData03 = group.get_group('0.3Msol')\n",
    "# plot_multiHistogram(tDiskData03, ['m', 'r', 't'], bins=50)\n",
    "\n",
    "# more tests\n",
    "# plot_multiHistogram(Mgrid.tDiskData, 'm', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create occurrence maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plots.plot_occurrence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot all maps into one figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix all ranges for better comparison of subpopulations\n",
    "smaRange = [1e-2, 50.] \n",
    "radRange = [2e-1, 400.]\n",
    "colRange = [0., 10.]\n",
    "\n",
    "fig, axes = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "\n",
    "for (label, population), ax in zip(Mgrid.tDiskData.groupby(level=0), axes.reshape(-1)):\n",
    "\n",
    "    h, x, y, ax, im = plots.plot_occurrence(population, xAxis='a', logColormap=True, xRange=smaRange,\n",
    "                                        yRange=radRange, zRange=colRange, showColorbar=False, ax=ax)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    t = ax.text(.07, .85, label[:-4] + ' M$_\\odot$', color='white', transform=ax.transAxes)\n",
    "\n",
    "    \n",
    "fig.text(0.45, 0.01, 'Semimajor Axis [au]', ha='center')\n",
    "fig.text(0.01, 0.55, 'Planet Size [$\\mathrm{R_{Earth}}$]', va='center', rotation='vertical')\n",
    "  \n",
    "cbar_ax = fig.add_axes([0.84, 0.13, 0.04, 0.84])\n",
    "cbarlabel = r\"Planets per 100 Stars per $a-R_P$ interval\"\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.set_label(cbarlabel, labelpad=5.)\n",
    "\n",
    "plt.subplots_adjust(left=.11, bottom=.13, right=.79, top=.97, wspace=.08, hspace=.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint simulation list - population analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read simulation lists into population\n",
    "simlistFiles = [outputs + s for s in ['simulation_list_0.3Msol.dat', 'simulation_list_0.5Msol.dat', 'simulation_list_0.7Msol.dat', 'simulation_list_1.0Msol.dat']]\n",
    "Mgrid.read_simlist(simlistFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check scaling of initial disk mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiHistogram(Mgrid.simlist, 'diskM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mgrid.simlist.groupby(level=0).diskM.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does the linear scaling function work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0,10)\n",
    "y = utils.linearScale(0,10,2,10,x)\n",
    "ax.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks good. Let's have a look how the distribution of 1.0Msol disk masses changes when scaled down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
